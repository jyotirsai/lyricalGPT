{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1Ph-fk_FbQyx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "import random\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.trainers import WordLevelTrainer, BpeTrainer\n",
        "from tokenizers.models import WordLevel, BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace"
      ],
      "metadata": {
        "id": "z0DpzAHsb2wV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhVq_o1Wb48m",
        "outputId": "49040abd-537f-4d37-c192-de8a2025d295"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'data_file_path': '/content/drive/My Drive/Notebooks/lyricalGPT/df_eng_pop_2015.csv',\n",
        "    'context_size': 64, # must be < max_token_length\n",
        "    'min_token_length': 100,\n",
        "    'max_token_length': 500,\n",
        "    'batch_size': 256,\n",
        "    'epochs': 100,\n",
        "    'n_heads': 8,\n",
        "    'n_layers': 6,\n",
        "    'embed_size': 512,\n",
        "    'ff_size': 2048,\n",
        "    'dropout': 0.1,\n",
        "    'lr': 3e-4,\n",
        "    'preload': 0,\n",
        "    'model_folder': 'lyricalGPT',\n",
        "    'model_basename': 'lyricalGPT',\n",
        "    'model_filename': 'lyricalGPT20.pt',\n",
        "    'tokenizer_file': 'tokenizer_{0}.json',\n",
        "}"
      ],
      "metadata": {
        "id": "lk8XWEvIb_xM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(file_path):\n",
        "    df = pd.read_csv(file_path, header=0)\n",
        "    data = [df['lyrics'][i] for i in range(len(df))]\n",
        "    return data"
      ],
      "metadata": {
        "id": "Yf0-i7kocI8z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text = prepare_data(config['data_file_path'])"
      ],
      "metadata": {
        "id": "oFS9wiXzcMjE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len(text)"
      ],
      "metadata": {
        "id": "5cvX-eebcUaw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text[0]"
      ],
      "metadata": {
        "id": "P6Yjr9kB7_Cw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_lyric(data):\n",
        "    for i in range(len(data)):\n",
        "        yield data[i]\n",
        "\n",
        "def build_tokenizer(config, raw_data):\n",
        "    tokenizer_path = Path(config[\"tokenizer_file\"])\n",
        "    if not Path.exists(tokenizer_path):\n",
        "        tokenizer = Tokenizer(BPE(unk_token=\"<UNK>\"))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = BpeTrainer(special_tokens=[\"<UNK>\", \"<PAD>\", \"<SOS>\", \"<EOS>\"])\n",
        "        tokenizer.train_from_iterator(\n",
        "            retrieve_lyric(raw_data), trainer=trainer\n",
        "        )\n",
        "        tokenizer.save(str(tokenizer_path))\n",
        "    else:\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "xVDTOyxLcWKT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer = build_tokenizer(config, text)"
      ],
      "metadata": {
        "id": "UoL9VvjSdqEY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Number of tokens:\", tokenizer.get_vocab_size())"
      ],
      "metadata": {
        "id": "4I8G2h6Jd_V6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#z = tokenizer.encode(text[0])\n",
        "#print(z.ids)"
      ],
      "metadata": {
        "id": "2-0LV5gEgK3r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(tokenizer.decode(z.ids))"
      ],
      "metadata": {
        "id": "OmMYBXM6gPs-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "max_seq_len = 0\n",
        "min_seq_len = 10000\n",
        "for t in text:\n",
        "    seq_len = len(tokenizer.encode(t).ids)\n",
        "    if seq_len > max_seq_len:\n",
        "        max_seq_len = seq_len\n",
        "\n",
        "    if seq_len < min_seq_len:\n",
        "        min_seq_len = seq_len\n",
        "print(\"Max sequence length: \", max_seq_len)\n",
        "print(\"Min sequence length: \", min_seq_len)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "3v-2oDjEhLhl",
        "outputId": "88495b81-15c7-474b-b092-1608335f92a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmax_seq_len = 0\\nmin_seq_len = 10000\\nfor t in text:\\n    seq_len = len(tokenizer.encode(t).ids)\\n    if seq_len > max_seq_len:\\n        max_seq_len = seq_len\\n\\n    if seq_len < min_seq_len:\\n        min_seq_len = seq_len\\nprint(\"Max sequence length: \", max_seq_len)\\nprint(\"Min sequence length: \", min_seq_len)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"original length: \", len(text))\n",
        "#new_text = [t for t in text if len(tokenizer.encode(t).ids) <= 500 and len(tokenizer.encode(t).ids) > 100]\n",
        "#print(\"new length: \", len(new_text))"
      ],
      "metadata": {
        "id": "nIWvHBoxhvRU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer.token_to_id(\"<SOS>\")"
      ],
      "metadata": {
        "id": "FPExbPgy4WgZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LyricsDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, context_size):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.context_size = context_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        lyric = self.data[idx]\n",
        "        input_ids = self.tokenizer.encode(lyric).ids\n",
        "\n",
        "        size = len(input_ids)-self.context_size\n",
        "        random_number = random.randint(0, size - 1)\n",
        "        x = torch.tensor(input_ids[random_number:random_number+self.context_size],dtype=torch.long)\n",
        "        y = torch.tensor(input_ids[random_number+1:random_number+self.context_size+1],dtype=torch.long)\n",
        "\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "KSsM6Q_BgRfd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = LyricsDataset(new_text, tokenizer, config['context_size'])"
      ],
      "metadata": {
        "id": "wEAAibdansOV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len(dataset)"
      ],
      "metadata": {
        "id": "MqG7UksgzDu0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x, y = dataset[0]"
      ],
      "metadata": {
        "id": "ogKRexs5n1Kz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x"
      ],
      "metadata": {
        "id": "oGk4c8pfn38j"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y"
      ],
      "metadata": {
        "id": "V4SEmv8rodcC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(tokenizer.decode(x.tolist()))"
      ],
      "metadata": {
        "id": "70mtZX4GoebJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(tokenizer.decode(y.tolist()))"
      ],
      "metadata": {
        "id": "L3dEtdw5oyw6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataloader_and_tokenizers(config):\n",
        "    text = prepare_data(config['data_file_path'])\n",
        "    tokenizer = build_tokenizer(config, text)\n",
        "    new_text = [t for t in text if len(tokenizer.encode(t).ids) > config['min_token_length']]\n",
        "    train_size = int(0.9 * len(new_text))\n",
        "    val_size = len(new_text) - train_size\n",
        "    raw_train, raw_val = random_split(new_text, [train_size, val_size])\n",
        "\n",
        "    train = LyricsDataset(\n",
        "        raw_train,\n",
        "        tokenizer,\n",
        "        config[\"context_size\"],\n",
        "    )\n",
        "    val = LyricsDataset(\n",
        "        raw_val,\n",
        "        tokenizer,\n",
        "        config[\"context_size\"],\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(train, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    val_dataloader = DataLoader(val, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "    return train_dataloader, val_dataloader, tokenizer"
      ],
      "metadata": {
        "id": "C5hfD4y2o17I"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train, val, tokenizer = build_dataloader_and_tokenizers(config)"
      ],
      "metadata": {
        "id": "HpRXO2tcrcZu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train.dataset[0]"
      ],
      "metadata": {
        "id": "uk3uouTprdob"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x,y = train.dataset[355]"
      ],
      "metadata": {
        "id": "Ms-oqg7p47-r"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(len(x), len(y))"
      ],
      "metadata": {
        "id": "oLyGLok05p-Q"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x.shape"
      ],
      "metadata": {
        "id": "7qu3KVZI52Pb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "  def __init__(self, embed_size: int, head_size: int, context_size: int, dropout: float):\n",
        "    super().__init__()\n",
        "    self.query = nn.Linear(embed_size, head_size)\n",
        "    self.key = nn.Linear(embed_size, head_size)\n",
        "    self.value = nn.Linear(embed_size, head_size)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(context_size, context_size)))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (batch_size, context_size, embed_size) --> (batch_size, context_size, head_size)\n",
        "\n",
        "    # (batch_size, context_size, head_size)\n",
        "    q, k, v = self.query(x), self.key(x), self.value(x)\n",
        "\n",
        "    # (batch_size, context_size, head_size) @ (batch_size, head_size, context_size) --> (batch_size, context_size, context_size)\n",
        "    attention_scores = (q @ k.transpose(-2,-1)) / math.sqrt(k.shape[-1])\n",
        "    attention_scores = attention_scores.masked_fill(self.tril[:, :] == 0, float('-inf'))\n",
        "    attention_scores = F.softmax(attention_scores, dim=-1)\n",
        "    attention_scores = self.dropout(attention_scores)\n",
        "\n",
        "    # (batch_size, context_size, context_size) @ (batch_size, context_size, head_size) --> (batch_size, context_size, head_size)\n",
        "    out = attention_scores @ v\n",
        "    return out"
      ],
      "metadata": {
        "id": "vcuRIDOa42Ca"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, embed_size: int, head_size: int, n_heads: int, context_size: int, dropout: float):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(embed_size, head_size, context_size, dropout) for _ in range(n_heads)])\n",
        "    self.linear = nn.Linear(head_size * n_heads, embed_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "    out = self.dropout(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "8ga0XaLJaXcJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "  def __init__(self, embed_size: int, ff_size: int, dropout: float) -> None:\n",
        "    super().__init__()\n",
        "    self.linear_1 = nn.Linear(embed_size, ff_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.linear_2 = nn.Linear(ff_size, embed_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (batch_size, context_size, embed_size) --> (batch_size, context_size, ff_size) --> (batch_size, context_size, embed_size)\n",
        "    return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"
      ],
      "metadata": {
        "id": "MY9cFNk8dXYK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, embed_size: int, n_heads: int, context_size: int, ff_size: int, dropout: float) -> None:\n",
        "    super().__init__()\n",
        "    assert embed_size % n_heads == 0, \"embed_size is not divisible by n_heads\"\n",
        "    head_size = embed_size // n_heads\n",
        "    self.multi_head_attention = MultiHeadAttention(embed_size, head_size, n_heads, context_size, dropout)\n",
        "    self.feed_forward = FeedForwardBlock(embed_size, ff_size, dropout)\n",
        "    self.lnorm = nn.ModuleList([nn.LayerNorm(embed_size) for _ in range(2)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.multi_head_attention(self.lnorm[0](x))\n",
        "    x = x + self.feed_forward(self.lnorm[1](x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "9JY1jUdXeL7l"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self, vocab_size: int, embed_size: int, n_heads: int, context_size: int, ff_size: int, n_layers: int, dropout: float) -> None:\n",
        "    super().__init__()\n",
        "    self.embeds = nn.Embedding(vocab_size, embed_size)\n",
        "    self.pos_embeds = nn.Embedding(context_size, embed_size)\n",
        "    self.decoder = nn.Sequential(*[DecoderBlock(embed_size, n_heads, context_size, ff_size, dropout) for _ in range(n_layers)])\n",
        "    self.fnorm = nn.LayerNorm(embed_size)\n",
        "    self.linear = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "  def forward(self, inputs, targets=None):\n",
        "    batch_size, context_size = inputs.shape\n",
        "\n",
        "    embeds = self.embeds(inputs)\n",
        "    pos_embeds = self.pos_embeds(torch.arange(context_size).to(inputs.device))\n",
        "    x = embeds + pos_embeds\n",
        "    x = self.decoder(x)\n",
        "    x = self.fnorm(x)\n",
        "    logits = self.linear(x)\n",
        "\n",
        "    if targets is not None:\n",
        "      batch_size, context_size, embed_size = logits.shape\n",
        "      logits = logits.view(batch_size*context_size, embed_size)\n",
        "      targets = targets.view(batch_size*context_size)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "    else:\n",
        "      loss = None\n",
        "\n",
        "    return logits, loss"
      ],
      "metadata": {
        "id": "Zq0t4QQpf829"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weights_file_path(config, epochs: str):\n",
        "  model_basename = config['model_basename']\n",
        "  model_filename = f\"{model_basename}{epochs}.pt\"\n",
        "  return str(Path('.') / model_filename)"
      ],
      "metadata": {
        "id": "1WLWiYkn5ysD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_val_loss(model, val, tokenizer, device):\n",
        "  model.eval()\n",
        "  running_vloss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i,(xb, yb) in enumerate(val):\n",
        "      logits, loss = model(xb.to(device), yb.to(device))\n",
        "      running_vloss += loss\n",
        "\n",
        "  avg_vloss = running_vloss / (i + 1)\n",
        "  print('LOSS valid {}'.format(avg_vloss))"
      ],
      "metadata": {
        "id": "jPdVdVxdfSXH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(config):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  print(f'Using device {device}')\n",
        "\n",
        "  train, val, tokenizer = build_dataloader_and_tokenizers(config)\n",
        "  model = GPTModel(tokenizer.get_vocab_size(), config['embed_size'], config['n_heads'], config['context_size'], config['embed_size']*4, config['n_layers'], config['dropout'])\n",
        "  model.to(device)\n",
        "\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'])\n",
        "\n",
        "  for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "  initial_epoch = 0\n",
        "  global_step = 0\n",
        "  if config['preload']:\n",
        "    model_filename = get_weights_file_path(config, config['preload'])\n",
        "    print(f'Preloading model: {model_filename}')\n",
        "    state = torch.load(model_filename)\n",
        "    initial_epoch = state['epoch'] + 1\n",
        "    optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "    model.load_state_dict(state['model_state_dict'])\n",
        "    global_step = state['global_step']\n",
        "\n",
        "  for epoch in range(initial_epoch, config['epochs']):\n",
        "    model.train()\n",
        "    batch_iterator = tqdm(train, desc=f'Processing epoch {epoch:02d}')\n",
        "    for (xb, yb) in batch_iterator:\n",
        "      logits, loss = model(xb.to(device), yb.to(device))\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      global_step += 1\n",
        "\n",
        "    estimate_val_loss(model, val, tokenizer, device)\n",
        "    print(\"LOSS train: \", loss)\n",
        "\n",
        "    # Save the model\n",
        "    model_filename = get_weights_file_path(config, f'{epoch:02d}')\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'global_step': global_step,\n",
        "    }, model_filename)"
      ],
      "metadata": {
        "id": "hTZGu_lGypsp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_model(config)"
      ],
      "metadata": {
        "id": "q0sprC0h5vIJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(config, max_new_tokens: int = 500):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Using device:\", device)\n",
        "\n",
        "  tokenizer = Tokenizer.from_file(str(Path('./'+config['tokenizer_file'])))\n",
        "\n",
        "  model = GPTModel(tokenizer.get_vocab_size(), config['embed_size'], config['n_heads'], config['context_size'], config['embed_size']*4, config['n_layers'], config['dropout'])\n",
        "  model.to(device)\n",
        "\n",
        "  state = torch.load('./'+config['model_filename'])\n",
        "  model.load_state_dict(state['model_state_dict'])\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  inputs = torch.randint(100,1000,(config['context_size'], config['context_size']), dtype=torch.long, device=device)\n",
        "  with torch.no_grad():\n",
        "    for _ in range(max_new_tokens):\n",
        "      inputs_cropped = inputs[:, -config['context_size']:]\n",
        "      logits, _ = model(inputs_cropped.to(device), None)\n",
        "      logits = logits[:, -1, :]\n",
        "      probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "      inputs_next = torch.multinomial(probs, 1)\n",
        "      inputs = torch.cat((inputs, inputs_next), dim=1)\n",
        "\n",
        "  return tokenizer.decode(inputs.squeeze()[0].tolist())"
      ],
      "metadata": {
        "id": "QzTwH66_RV1Q"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = generate(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKPYuL_w6UZ2",
        "outputId": "74b16220-e058-4d7c-f1e0-5d0b09bdc281"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFGhjXJu6vby",
        "outputId": "a06e51a0-75f3-4c31-ca4e-78bbe64ed619"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2562"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0:600]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "HZkg2uz-6wvs",
        "outputId": "61de280b-c8f9-4ccd-85db-c57f49714455"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'babe feet wear hell coming hold head Of ocean sorry play Santa somewhere Show hands kids Get Without Mr green longer pass alive comin won d again hundred against learned mad past minute against walked floor played alive y believe second wasn hair wish ago bring break His goes beat used cool until Black cause doin Before funny Its dance took men fast pretty keep The down So by Him what arms strong me cheese my gentle or hard Speaking blurred now window or down . Mix now real me thinking talking unafraid my dies \" window As jammed old hurts on it weep into take turns all dusk in hear on My Alway'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[700:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "OttTQGhn7aAh",
        "outputId": "c6736d5a-e0dc-4619-8546-b152bfacdacd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ear kind hard skull to hard rain hear end or With loved Is home on it hard WOULD His you mass You hard Going he home on it were to As [ hard leavin yellow Wings to Gives at black some me when she ever not need on My equal aches hear around Sweeter hear city you hurts Oh now hear monkey hard instead '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZWpDa6Lk5ps"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}